{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Clasificaci√≥n por machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import ast\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "# Linear Models \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>listOfCleanWords</th>\n",
       "      <th>cleanWordsAsText</th>\n",
       "      <th>BagOfWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['explanation', 'edits', 'made', 'username', '...</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['aww', 'match', 'background', 'colour', 'seem...</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['hey', 'man', 'really', 'trying', 'edit', 'wa...</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['make', 'real', 'suggestion', 'improvement', ...</td>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sir', 'hero', 'chance', 'remember', 'page']</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['congratulation', 'well', 'use', 'tool', 'wel...</td>\n",
       "      <td>congratulation well use tool well talk</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['cocksucker', 'piss', 'around', 'work']</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['vandalism', 'matt', 'shirvington', 'article'...</td>\n",
       "      <td>vandalism matt shirvington article reverted pl...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sorry', 'word', 'nonsense', 'offensive', 'an...</td>\n",
       "      <td>sorry word nonsense offensive anyway intending...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['alignment', 'subject', 'contrary', 'dulithgow']</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "5           5  00025465d4725e87   \n",
       "6           6  0002bcb3da6cb337   \n",
       "7           7  00031b1e95af7921   \n",
       "8           8  00037261f536c51d   \n",
       "9           9  00040093b2687caa   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0             0   \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1             1   \n",
       "7  Your vandalism to the Matt Shirvington article...      0             0   \n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0             0   \n",
       "9  alignment on this subject and which are contra...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "5        0       0       0              0   \n",
       "6        1       0       1              0   \n",
       "7        0       0       0              0   \n",
       "8        0       0       0              0   \n",
       "9        0       0       0              0   \n",
       "\n",
       "                                    listOfCleanWords  \\\n",
       "0  ['explanation', 'edits', 'made', 'username', '...   \n",
       "1  ['aww', 'match', 'background', 'colour', 'seem...   \n",
       "2  ['hey', 'man', 'really', 'trying', 'edit', 'wa...   \n",
       "3  ['make', 'real', 'suggestion', 'improvement', ...   \n",
       "4      ['sir', 'hero', 'chance', 'remember', 'page']   \n",
       "5  ['congratulation', 'well', 'use', 'tool', 'wel...   \n",
       "6           ['cocksucker', 'piss', 'around', 'work']   \n",
       "7  ['vandalism', 'matt', 'shirvington', 'article'...   \n",
       "8  ['sorry', 'word', 'nonsense', 'offensive', 'an...   \n",
       "9  ['alignment', 'subject', 'contrary', 'dulithgow']   \n",
       "\n",
       "                                    cleanWordsAsText      BagOfWords  \n",
       "0  explanation edits made username hardcore metal...  <class 'dict'>  \n",
       "1  aww match background colour seemingly stuck th...  <class 'dict'>  \n",
       "2  hey man really trying edit war guy constantly ...  <class 'dict'>  \n",
       "3  make real suggestion improvement wondered sect...  <class 'dict'>  \n",
       "4                      sir hero chance remember page  <class 'dict'>  \n",
       "5             congratulation well use tool well talk  <class 'dict'>  \n",
       "6                        cocksucker piss around work  <class 'dict'>  \n",
       "7  vandalism matt shirvington article reverted pl...  <class 'dict'>  \n",
       "8  sorry word nonsense offensive anyway intending...  <class 'dict'>  \n",
       "9               alignment subject contrary dulithgow  <class 'dict'>  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameTrainCSV = 'trainWithListOfCleanWords'\n",
    "nameTestCSV = 'testWithListOfCleanWords'\n",
    "\n",
    "train = pd.read_csv('../data/processed/' + nameTrainCSV + '.csv', encoding='utf-8')\n",
    "train['BagOfWords'] = dict\n",
    "train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.237758874893188\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for x in range(len(train)):\n",
    "    train.set_value(col='listOfCleanWords',\n",
    "                index=x,\n",
    "                value=ast.literal_eval(train[\"listOfCleanWords\"][x]))\n",
    "    train.set_value(col='BagOfWords',\n",
    "                index=x,\n",
    "                value=Counter(train[\"listOfCleanWords\"][x]))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>listOfCleanWords</th>\n",
       "      <th>cleanWordsAsText</th>\n",
       "      <th>BagOfWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>{'explanation': 1, 'edits': 1, 'made': 1, 'use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[aww, match, background, colour, seemingly, st...</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "      <td>{'aww': 1, 'match': 1, 'background': 1, 'colou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>{'hey': 1, 'man': 1, 'really': 1, 'trying': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[make, real, suggestion, improvement, wondered...</td>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "      <td>{'make': 1, 'real': 1, 'suggestion': 1, 'impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>{'sir': 1, 'hero': 1, 'chance': 1, 'remember':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "\n",
       "                                    listOfCleanWords  \\\n",
       "0  [explanation, edits, made, username, hardcore,...   \n",
       "1  [aww, match, background, colour, seemingly, st...   \n",
       "2  [hey, man, really, trying, edit, war, guy, con...   \n",
       "3  [make, real, suggestion, improvement, wondered...   \n",
       "4                [sir, hero, chance, remember, page]   \n",
       "\n",
       "                                    cleanWordsAsText  \\\n",
       "0  explanation edits made username hardcore metal...   \n",
       "1  aww match background colour seemingly stuck th...   \n",
       "2  hey man really trying edit war guy constantly ...   \n",
       "3  make real suggestion improvement wondered sect...   \n",
       "4                      sir hero chance remember page   \n",
       "\n",
       "                                          BagOfWords  \n",
       "0  {'explanation': 1, 'edits': 1, 'made': 1, 'use...  \n",
       "1  {'aww': 1, 'match': 1, 'background': 1, 'colou...  \n",
       "2  {'hey': 1, 'man': 1, 'really': 1, 'trying': 1,...  \n",
       "3  {'make': 1, 'real': 1, 'suggestion': 1, 'impro...  \n",
       "4  {'sir': 1, 'hero': 1, 'chance': 1, 'remember':...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MULTICLASS PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classLabel = {\n",
    "    0: \"neutral\",\n",
    "    1: \"toxic\",\n",
    "    2 : \"severe_toxic\",\n",
    "    3 : \"obscene\",\n",
    "    4 : \"threat\",\n",
    "    5 : \"insult\",\n",
    "    6 : \"identity_hate\" \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get texts in Toxic and No Toxic\n",
    "y = np.empty((len(train['cleanWordsAsText']),),dtype=object)\n",
    "allTextToxicTrain = dict()\n",
    "for idx in classLabel:\n",
    "    if classLabel[idx] != \"neutral\":\n",
    "        T = np.where(train[classLabel[idx]] == 1)[0]\n",
    "        allTextToxicTrain[idx] = T\n",
    "        for i in T:\n",
    "            if y[i] is None:\n",
    "                y[i] = [idx]                \n",
    "            else:\n",
    "                y[i].append(idx)\n",
    "indxsOfNeutralTexts = np.where(y == None) \n",
    "y[indxsOfNeutralTexts] = [[0]]\n",
    "indxsOfNeutralTexts = indxsOfNeutralTexts[0]\n",
    "\n",
    "allTextsNoToxicTrain = [str(train['cleanWordsAsText'][x]) for x in indxsOfNeutralTexts]\n",
    "\n",
    "idxList = []\n",
    "for i in allTextToxicTrain.keys():\n",
    "    #allTextToxicTrain[i] = [str(train['cleanWordsAsText'][j]) for j in allTextToxicTrain[i]]\n",
    "    idxList = np.unique(np.append(idxList, allTextToxicTrain[i]))\n",
    "allTextToxicTrain = [str(train['cleanWordsAsText'][j]) for j in idxList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>listOfCleanWords</th>\n",
       "      <th>cleanWordsAsText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>['yo', 'bitch', 'ja', 'rule', 'succesful', 'ev...</td>\n",
       "      <td>yo bitch ja rule succesful ever whats hating s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>['rfc', 'title', 'fine', 'imo']</td>\n",
       "      <td>rfc title fine imo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>['source', 'zawe', 'ashton', 'lapland']</td>\n",
       "      <td>source zawe ashton lapland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>['look', 'back', 'source', 'information', 'upd...</td>\n",
       "      <td>look back source information updated correct f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>['anonymously', 'edit', 'article']</td>\n",
       "      <td>anonymously edit article</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  00001cee341fdb12   \n",
       "1           1  0000247867823ef7   \n",
       "2           2  00013b17ad220c46   \n",
       "3           3  00017563c3f7919a   \n",
       "4           4  00017695ad8997eb   \n",
       "\n",
       "                                        comment_text  \\\n",
       "0  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  :If you have a look back at the source, the in...   \n",
       "4          I don't anonymously edit articles at all.   \n",
       "\n",
       "                                    listOfCleanWords  \\\n",
       "0  ['yo', 'bitch', 'ja', 'rule', 'succesful', 'ev...   \n",
       "1                    ['rfc', 'title', 'fine', 'imo']   \n",
       "2            ['source', 'zawe', 'ashton', 'lapland']   \n",
       "3  ['look', 'back', 'source', 'information', 'upd...   \n",
       "4                 ['anonymously', 'edit', 'article']   \n",
       "\n",
       "                                    cleanWordsAsText  \n",
       "0  yo bitch ja rule succesful ever whats hating s...  \n",
       "1                                 rfc title fine imo  \n",
       "2                         source zawe ashton lapland  \n",
       "3  look back source information updated correct f...  \n",
       "4                           anonymously edit article  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test clasification\n",
    "test = pd.read_csv('../data/processed/' + nameTestCSV + '.csv', encoding='utf-8')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se inicializan las variables de X_train y X_test + Y_train completos a partir de los textos ya limpios, ademas de obtener todos los textos en forma de lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allTrainText = [txt if txt is not np.nan else '' for txt in train['cleanWordsAsText']]\n",
    "allTestText = [txt if txt is not np.nan else '' for txt in test['cleanWordsAsText']]\n",
    "X_train = allTrainText\n",
    "X_test = allTestText\n",
    "yBinary = MultiLabelBinarizer().fit_transform(y)\n",
    "y_train = yBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\"idExp\",\"numFeatures\", \"algorithm\", \"Nfolds\", \"accuaracy\", \"logloss\", \"fmeasure\"]\n",
    "dfTestResults = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Clasificadores Machine Learning\n",
    "\n",
    "> Inicializamos los clasificadores con las variables a utilizar de cada uno de ellos. Los clasificadores a utilizar s√≥n:\n",
    "> - Regresi√≥n Logistica (LR)\n",
    "> - M√°quinas de soporte vectorial con un kernel lineal (Linear SVC)\n",
    "> - Naive Bayes (NB)\n",
    "> - Stochastic Gradient Descent (SGD)\n",
    "> - √Årbol de decisi√≥n (DT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Classifiers\n",
    "\n",
    "# Logistic Regresion\n",
    "clfLR = OneVsRestClassifier(LogisticRegression(C=5))\n",
    "\n",
    "# Linear SVC\n",
    "clfLSVC = OneVsRestClassifier(LinearSVC(C=5))\n",
    "\n",
    "# Naive Bayes\n",
    "clfNB = OneVsRestClassifier(MultinomialNB())\n",
    "\n",
    "# SGD\n",
    "clfSGD = OneVsRestClassifier(SGDClassifier(loss=\"log\"))\n",
    "\n",
    "# Decision Tree\n",
    "clfDT = OneVsRestClassifier(DecisionTreeClassifier(max_depth=8))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedings\n",
    "> En este apartado se dise√±an 2 formas de representaci√≥n de las palabras de los textos, utilizando directamente los textos ya limpiados previamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mediante vector TFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFeatures = 158627\n"
     ]
    }
   ],
   "source": [
    "# Vectorizer all text\n",
    "maxF = 158627\n",
    "tdifV = TfidfVectorizer(ngram_range=(1,6), max_features=maxF)\n",
    "X_train_tdif = tdifV.fit_transform(allTrainText)\n",
    "\n",
    "numFeaturesTFID = len(tdifV.get_feature_names())\n",
    "print(\"NFeatures = \" + str(numFeaturesTFID))\n",
    "tdifVTest = TfidfVectorizer(vocabulary=tdifV.get_feature_names())\n",
    "X_test_tdif = tdifVTest.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mediante BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BOW\n",
    "bowFeatures = CountVectorizer(vocabulary=tdifV.get_feature_names())\n",
    "X_train_bow = bowFeatures.fit_transform(allTrainText)\n",
    "X_test_bow = bowFeatures.fit_transform(allTestText)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "> En este apartado se indicar√°n los parametros a tener en cuenta en los experimentos de train haciendo uso de CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation\n",
    "Nfolds = 5\n",
    "kf = KFold(n_splits=Nfolds, random_state=True)\n",
    "kf.get_n_splits(X_train_tdif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Para tener un seguimiento de los experimentos realizados, se dispondr√° de un id de experimento, para n√∫merar el experimento a realizar, que posteriormente estos ser√°n guardados en formato excel.\n",
    "> Para la asignaci√≥n X_train, est√° podr√° ser asignada por cualquiera de los 2 word embedings creados previamente ya sea TFID o BOW. Adem√°s se deber√° asignar el numFeatures del word embeding utilizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV experiments\n",
    "idExp = 0\n",
    "X_train = X_train_tdif\n",
    "X_test = X_test_tdif\n",
    "numFeatures = numFeaturesTFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR SVC CV exp\n",
    "name = \"Linear SVC\"\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_cv = X[train_index]\n",
    "    X_test_cv = X[test_index]\n",
    "    y_train_cv, y_test_cv = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    clfLSVC.fit(X_train_cv, y_train_cv)\n",
    "    predicted = clfLSVC.predict(X_test_cv)\n",
    "    acc = accuracy_score(y_test_cv, predicted)\n",
    "    fmeausre = f1_score(y_test_cv, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test_cv)\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "dfTestResults.loc[idExp] = [idExp,len(tdifV.get_feature_names()),name,Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "print(str(idExp))\n",
    "idExp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regresion CV exp\n",
    "name = \"Logistic Regresion\"\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_cv = X[train_index]\n",
    "    X_test_cv = X[test_index]\n",
    "    y_train_cv, y_test_cv = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    clfLR.fit(X_train_cv, y_train_cv)\n",
    "    predicted = clfLR.predict(X_test_cv)\n",
    "    acc = accuracy_score(y_test_cv, predicted)\n",
    "    fmeausre = f1_score(y_test_cv, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test_cv)\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "dfTestResults.loc[idExp] = [idExp,len(tdifV.get_feature_names()),name,Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "print(str(idExp))\n",
    "idExp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD CV exp\n",
    "name = \"SGD\"\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_cv = X[train_index]\n",
    "    X_test_cv = X[test_index]\n",
    "    y_train_cv, y_test_cv = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    clfSGD.fit(X_train_cv, y_train_cv)\n",
    "    predicted = clfSGD.predict(X_test_cv)\n",
    "    acc = accuracy_score(y_test_cv, predicted)\n",
    "    fmeausre = f1_score(y_test_cv, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test_cv)\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "dfTestResults.loc[idExp] = [idExp,len(tdifV.get_feature_names()),name,Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "print(str(idExp))\n",
    "idExp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB CV exp\n",
    "name = \"NB\"\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_cv = X[train_index]\n",
    "    X_test_cv = X[test_index]\n",
    "    y_train_cv, y_test_cv = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    clfNB.fit(X_train_cv, y_train_cv)\n",
    "    predicted = clfNB.predict(X_test_cv)\n",
    "    acc = accuracy_score(y_test_cv, predicted)\n",
    "    fmeausre = f1_score(y_test_cv, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test_cv)\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "dfTestResults.loc[idExp] = [idExp,len(tdifV.get_feature_names()),name,Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "print(str(idExp))\n",
    "idExp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree CV exp\n",
    "name = \"Decision Tree\"\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_cv = X[train_index]\n",
    "    X_test_cv = X[test_index]\n",
    "    y_train_cv, y_test_cv = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    clfDT.fit(X_train_cv, y_train_cv)\n",
    "    predicted = clfDT.predict(X_test_cv)\n",
    "    acc = accuracy_score(y_test_cv, predicted)\n",
    "    fmeausre = f1_score(y_test_cv, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test_cv)\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "dfTestResults.loc[idExp] = [idExp,len(tdifV.get_feature_names()),name,Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "print(str(idExp))\n",
    "idExp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTestResults.to_excel('report2.xls', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creaci√≥n de submisions de TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get submision from test\n",
    "def getCSVSubmision(prediction, name):\n",
    "    columns = [\"id\",\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "    dfTestPredicted = pd.DataFrame(columns=columns)\n",
    "    for x in tqdm(range(len(test))):\n",
    "        dfTestPredicted.loc[x] = [test['id'][x], prediction[x][1], prediction[x][2], prediction[x][3], prediction[x][4], prediction[x][5], prediction[x][6]]\n",
    "\n",
    "    dfTestPredicted.to_csv('../reports/testPred/'+ str(name) +'.csv',encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creaci√≥n de pruebas para submision de test mediante TFID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train_tdif\n",
    "X_test = X_test_tdif\n",
    "numFeatures = numFeaturesTFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit all clasificators with TFID matrix\n",
    "clfLSVC.fit(X_train, y_train)\n",
    "clfLR.fit(X_train, y_train)\n",
    "clfSGD.fit(X_train, y_train)\n",
    "clfNB.fit(X_train, y_train)\n",
    "clfDT.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addInfo = str(numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñé         | 5459/153164 [00:09<04:27, 551.22it/s]C:\\Anaconda2\\envs\\py36\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 85046/153164 [12:58<10:23, 109.21it/s]"
     ]
    }
   ],
   "source": [
    "getCSVSubmision(prediction=clfLSVC.predict(X_test),name=\"LSVC_TFID\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfLR.predict_proba(X_test), name=\"LR_TFID\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfSGD.predict_proba(X_test), name=\"SGD_TFID\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfNB.predict_proba(X_test), name=\"NB_TFID\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfDT.predict_proba(X_test), name=\"DT_TFID\" + addInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creaci√≥n de pruebas para submision de test mediante BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train_bow\n",
    "X_test = X_test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all clasificators with BOW matrix\n",
    "print(\"NFeatures = \" + str(len(tdifV.get_feature_names())))\n",
    "tdifVTest = TfidfVectorizer(vocabulary=tdifV.get_feature_names())\n",
    "X_test_tdif = tdifVTest.fit_transform(X_test)\n",
    "\n",
    "clfLSVC.fit(X_train, y_train)\n",
    "clfLR.fit(X_train, y_train)\n",
    "clfSGD.fit(X_train, y_train)\n",
    "clfNB.fit(X_train, y_train)\n",
    "clfDT.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfLSVC.predict(X_test),name=\"LSVC_BOW\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfLR.predict_proba(X_test), name=\"LR_BOW\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfSGD.predict_proba(X_test), name=\"SGD_BOW\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfNB.predict_proba(X_test), name=\"NB_BOW\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfDT.predict_proba(X_test), name=\"DT_BOW\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
