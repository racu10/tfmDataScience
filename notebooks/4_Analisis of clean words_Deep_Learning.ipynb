{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Clasificaci칩n por Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### En este notebook, se proceder치 al uso de algoritmos esclusivamente de Deep Learning, mediante los datos que han sido previamente limpiados por \"Clean Words\". En este encontraremos en primer lugar, la utilizaci칩n de Cross Validation entre los datos de entrenamiento, y posteriormente se realizar치 una prediccion sobre los datos de Test. Para poder ser evaluados por Kaggle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import ast\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "# Linear Models \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, LSTM, Input, RNN\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>listOfCleanWords</th>\n",
       "      <th>cleanWordsAsText</th>\n",
       "      <th>BagOfWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['explanation', 'edit', 'make', 'username', 'h...</td>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['aww', 'match', 'background', 'colour', 'seem...</td>\n",
       "      <td>aww match background colour seemingly stick th...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['hey', 'man', 'really', 'try', 'edit', 'war',...</td>\n",
       "      <td>hey man really try edit war guy constantly rem...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['make', 'real', 'suggestions', 'improvement',...</td>\n",
       "      <td>make real suggestions improvement wonder secti...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sir', 'hero', 'chance', 'remember', 'page']</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['congratulations', 'well', 'use', 'tool', 'we...</td>\n",
       "      <td>congratulations well use tool well talk</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['cocksucker', 'piss', 'around', 'work']</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['vandalism', 'matt', 'shirvington', 'article'...</td>\n",
       "      <td>vandalism matt shirvington article revert plea...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sorry', 'word', 'nonsense', 'offensive', 'an...</td>\n",
       "      <td>sorry word nonsense offensive anyway intend wr...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['alignment', 'subject', 'contrary', 'dulithgow']</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0             0        0       0       0              0   \n",
       "1             0        0       0       0              0   \n",
       "2             0        0       0       0              0   \n",
       "3             0        0       0       0              0   \n",
       "4             0        0       0       0              0   \n",
       "5             0        0       0       0              0   \n",
       "6             1        1       0       1              0   \n",
       "7             0        0       0       0              0   \n",
       "8             0        0       0       0              0   \n",
       "9             0        0       0       0              0   \n",
       "\n",
       "                                    listOfCleanWords  \\\n",
       "0  ['explanation', 'edit', 'make', 'username', 'h...   \n",
       "1  ['aww', 'match', 'background', 'colour', 'seem...   \n",
       "2  ['hey', 'man', 'really', 'try', 'edit', 'war',...   \n",
       "3  ['make', 'real', 'suggestions', 'improvement',...   \n",
       "4      ['sir', 'hero', 'chance', 'remember', 'page']   \n",
       "5  ['congratulations', 'well', 'use', 'tool', 'we...   \n",
       "6           ['cocksucker', 'piss', 'around', 'work']   \n",
       "7  ['vandalism', 'matt', 'shirvington', 'article'...   \n",
       "8  ['sorry', 'word', 'nonsense', 'offensive', 'an...   \n",
       "9  ['alignment', 'subject', 'contrary', 'dulithgow']   \n",
       "\n",
       "                                    cleanWordsAsText      BagOfWords  \n",
       "0  explanation edit make username hardcore metall...  <class 'dict'>  \n",
       "1  aww match background colour seemingly stick th...  <class 'dict'>  \n",
       "2  hey man really try edit war guy constantly rem...  <class 'dict'>  \n",
       "3  make real suggestions improvement wonder secti...  <class 'dict'>  \n",
       "4                      sir hero chance remember page  <class 'dict'>  \n",
       "5            congratulations well use tool well talk  <class 'dict'>  \n",
       "6                        cocksucker piss around work  <class 'dict'>  \n",
       "7  vandalism matt shirvington article revert plea...  <class 'dict'>  \n",
       "8  sorry word nonsense offensive anyway intend wr...  <class 'dict'>  \n",
       "9               alignment subject contrary dulithgow  <class 'dict'>  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameTrainCSV = 'trainWithListOfCleanWords'\n",
    "nameTestCSV = 'testWithListOfCleanWords'\n",
    "\n",
    "train = pd.read_csv('../data/processed/' + nameTrainCSV + '.csv', encoding='utf-8')\n",
    "train['BagOfWords'] = dict\n",
    "train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|郊걱둗郊걱둗郊걱둞    | 82334/159571 [00:09<00:09, 8311.11it/s]C:\\Anaconda2\\envs\\py36\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 159571/159571 [00:19<00:00, 8243.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.36321449279785\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for x in tqdm(range(len(train))):\n",
    "    train.set_value(col='listOfCleanWords',\n",
    "                index=x,\n",
    "                value=ast.literal_eval(train[\"listOfCleanWords\"][x]))\n",
    "    train.set_value(col='cleanWordsAsText',\n",
    "                index=x,\n",
    "                value=str(train[\"cleanWordsAsText\"][x]))\n",
    "    train.set_value(col='BagOfWords',\n",
    "                index=x,\n",
    "                value=Counter(train[\"listOfCleanWords\"][x]))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>listOfCleanWords</th>\n",
       "      <th>cleanWordsAsText</th>\n",
       "      <th>BagOfWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[explanation, edit, make, username, hardcore, ...</td>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "      <td>{'explanation': 1, 'edit': 1, 'make': 1, 'user...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[aww, match, background, colour, seemingly, st...</td>\n",
       "      <td>aww match background colour seemingly stick th...</td>\n",
       "      <td>{'aww': 1, 'match': 1, 'background': 1, 'colou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hey, man, really, try, edit, war, guy, consta...</td>\n",
       "      <td>hey man really try edit war guy constantly rem...</td>\n",
       "      <td>{'hey': 1, 'man': 1, 'really': 1, 'try': 1, 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[make, real, suggestions, improvement, wonder,...</td>\n",
       "      <td>make real suggestions improvement wonder secti...</td>\n",
       "      <td>{'make': 1, 'real': 1, 'suggestions': 1, 'impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>{'sir': 1, 'hero': 1, 'chance': 1, 'remember':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0             0        0       0       0              0   \n",
       "1             0        0       0       0              0   \n",
       "2             0        0       0       0              0   \n",
       "3             0        0       0       0              0   \n",
       "4             0        0       0       0              0   \n",
       "\n",
       "                                    listOfCleanWords  \\\n",
       "0  [explanation, edit, make, username, hardcore, ...   \n",
       "1  [aww, match, background, colour, seemingly, st...   \n",
       "2  [hey, man, really, try, edit, war, guy, consta...   \n",
       "3  [make, real, suggestions, improvement, wonder,...   \n",
       "4                [sir, hero, chance, remember, page]   \n",
       "\n",
       "                                    cleanWordsAsText  \\\n",
       "0  explanation edit make username hardcore metall...   \n",
       "1  aww match background colour seemingly stick th...   \n",
       "2  hey man really try edit war guy constantly rem...   \n",
       "3  make real suggestions improvement wonder secti...   \n",
       "4                      sir hero chance remember page   \n",
       "\n",
       "                                          BagOfWords  \n",
       "0  {'explanation': 1, 'edit': 1, 'make': 1, 'user...  \n",
       "1  {'aww': 1, 'match': 1, 'background': 1, 'colou...  \n",
       "2  {'hey': 1, 'man': 1, 'really': 1, 'try': 1, 'e...  \n",
       "3  {'make': 1, 'real': 1, 'suggestions': 1, 'impr...  \n",
       "4  {'sir': 1, 'hero': 1, 'chance': 1, 'remember':...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MULTICLASS PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classLabel = {\n",
    "    0: \"neutral\",\n",
    "    1: \"toxic\",\n",
    "    2 : \"severe_toxic\",\n",
    "    3 : \"obscene\",\n",
    "    4 : \"threat\",\n",
    "    5 : \"insult\",\n",
    "    6 : \"identity_hate\" \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.empty((len(train['cleanWordsAsText']),),dtype=object)\n",
    "allTextToxicTrain = dict()\n",
    "for idx in classLabel:\n",
    "    if classLabel[idx] != \"neutral\":\n",
    "        T = np.where(train[classLabel[idx]] == 1)[0]\n",
    "        allTextToxicTrain[idx] = T\n",
    "        for i in T:\n",
    "            if y[i] is None:\n",
    "                y[i] = [idx]                \n",
    "            else:\n",
    "                y[i].append(idx)\n",
    "indxsOfNeutralTexts = np.where(y == None) \n",
    "y[indxsOfNeutralTexts] = [[0]]\n",
    "indxsOfNeutralTexts = indxsOfNeutralTexts[0]\n",
    "\n",
    "allTextsNoToxicTrain = [str(train['cleanWordsAsText'][x]) for x in indxsOfNeutralTexts]\n",
    "\n",
    "idxList = []\n",
    "for i in allTextToxicTrain.keys():\n",
    "    #allTextToxicTrain[i] = [str(train['cleanWordsAsText'][j]) for j in allTextToxicTrain[i]]\n",
    "    idxList = np.unique(np.append(idxList, allTextToxicTrain[i]))\n",
    "allTextToxicTrain = [str(train['cleanWordsAsText'][j]) for j in idxList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>listOfCleanWords</th>\n",
       "      <th>cleanWordsAsText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>['yo', 'bitch', 'ja', 'rule', 'succesful', 'ev...</td>\n",
       "      <td>yo bitch ja rule succesful ever whats hat sad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>['rfc', 'title', 'fine', 'imo']</td>\n",
       "      <td>rfc title fine imo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>['source', 'zawe', 'ashton', 'lapland']</td>\n",
       "      <td>source zawe ashton lapland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>['look', 'back', 'source', 'information', 'upd...</td>\n",
       "      <td>look back source information update correct fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>['anonymously', 'edit', 'article']</td>\n",
       "      <td>anonymously edit article</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "                                    listOfCleanWords  \\\n",
       "0  ['yo', 'bitch', 'ja', 'rule', 'succesful', 'ev...   \n",
       "1                    ['rfc', 'title', 'fine', 'imo']   \n",
       "2            ['source', 'zawe', 'ashton', 'lapland']   \n",
       "3  ['look', 'back', 'source', 'information', 'upd...   \n",
       "4                 ['anonymously', 'edit', 'article']   \n",
       "\n",
       "                                    cleanWordsAsText  \n",
       "0  yo bitch ja rule succesful ever whats hat sad ...  \n",
       "1                                 rfc title fine imo  \n",
       "2                         source zawe ashton lapland  \n",
       "3  look back source information update correct fo...  \n",
       "4                           anonymously edit article  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test clasification\n",
    "test = pd.read_csv('../data/processed/' + nameTestCSV + '.csv', encoding='utf-8')\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se inicializan las variables de X_train y X_test + Y_train completos a partir de los textos ya limpios, ademas de obtener todos los textos en forma de lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allTrainText = [txt if txt is not np.nan else '' for txt in train['cleanWordsAsText']]\n",
    "allTestText = [txt if txt is not np.nan else '' for txt in test['cleanWordsAsText']]\n",
    "X_train = allTrainText\n",
    "X_test = allTestText\n",
    "yBinary = MultiLabelBinarizer().fit_transform(y)\n",
    "y_train = yBinary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\"idExp\",\"numFeatures\", \"algorithm\", \"Nfolds\", \"accuaracy\", \"logloss\", \"fmeasure\"]\n",
    "dfTestResults = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Cantidad features a utilizar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxFeatures = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedings\n",
    "> En este apartado se dise침an 3 formas de representaci칩n de las palabras de los textos, utilizando directamente los textos ya limpiados previamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mediante Tokenizaci칩n de las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "\n",
    "tokenizer = Tokenizer(num_words=maxFeatures)\n",
    "tokenizer.fit_on_texts(list(allTrainText))\n",
    "X_train_tokenized_seq = tokenizer.texts_to_sequences(allTrainText)\n",
    "X_test_tokenized_seq = tokenizer.texts_to_sequences(allTestText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156860"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_seq = pad_sequences(X_train_tokenized_seq)\n",
    "X_test_seq = pad_sequences(X_test_tokenized_seq, maxlen=len(X_train_seq[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Selecci칩n de features a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train_seq\n",
    "X_test = X_test_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creaci칩n del modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         15957100  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         89728     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 128)         114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 16,166,003\n",
      "Trainable params: 16,166,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MODEL CNN\n",
    "numClases = 7\n",
    "\n",
    "#training params\n",
    "batch_size = 512 \n",
    "num_epochs = 8 \n",
    "\n",
    "#model parameters\n",
    "num_filters = 128 \n",
    "weight_decay = 1e-4\n",
    "outputDim = 100\n",
    "\n",
    "modelCNN = Sequential()\n",
    "modelCNN.add(Embedding(input_dim=len(X_train), output_dim=outputDim))\n",
    "modelCNN.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
    "modelCNN.add(MaxPooling1D(2))\n",
    "modelCNN.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
    "modelCNN.add(GlobalMaxPooling1D())\n",
    "modelCNN.add(Dropout(0.5))\n",
    "modelCNN.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "modelCNN.add(Dense(numClases, activation='sigmoid'))  #multi-label (k-hot encoding)\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "modelCNN.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "modelCNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV experiments\n",
    "idExp = 0\n",
    "numFeatures = maxFeatures\n",
    "\n",
    "# Cross validation\n",
    "Nfolds = 2\n",
    "kf = KFold(n_splits=Nfolds, random_state=True)\n",
    "kf.get_n_splits(X_train)\n",
    "\n",
    "name = \"CNN\"\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "\n",
    "batch_size = 64 \n",
    "num_epochs = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in tqdm(kf.split(X_train)):\n",
    "    X_train_cv = X_train[train_index]\n",
    "    X_test_cv = X_train[test_index]\n",
    "    y_train_cv, y_test_cv = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    cnnmModelHist = modelCNN.fit(X_train_cv, y_train_cv, batch_size=batch_size, epochs=num_epochs, validation_split=0.1, shuffle=True, verbose=2)\n",
    "    predicted = modelCNN.predict(X_test_cv)\n",
    "\n",
    "    acc = accuracy_score(y_test_cv, predicted.round())\n",
    "    fmeausre = f1_score(y_test_cv, predicted.round(), labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted.round(), y_true=y_test_cv)\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "dfTestResults.loc[idExp] = [idExp,maxFeatures,name,Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "print(str(idExp))\n",
    "idExp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dfTestResults.to_excel('../reports/reportsCNN'+ str(maxFeatures) + '.xls', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicci칩n sobre test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> En este caso hacemos fitting mediante Tokenizaci칩n, debido a que para clasificar textos a partir de CNN es la que mejor resultados da. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/3\n",
      " - 2197s - loss: 0.1525 - acc: 0.9544 - val_loss: 0.0704 - val_acc: 0.9759\n",
      "Epoch 2/3\n",
      " - 2184s - loss: 0.0611 - acc: 0.9788 - val_loss: 0.0605 - val_acc: 0.9787\n",
      "Epoch 3/3\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "cnnmModelHist = modelCNN.fit(X_train, y_train, batch_size=batch_size, epochs=min(num_epochs, 3), validation_split=0.1, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = modelCNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se almacenan los datos predecidos en formato CSV para poder hacer el submision de test, y poder evaluar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"id\",\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "dfTestPredicted = pd.DataFrame(columns=columns)\n",
    "for x in tqdm(range(len(test))):\n",
    "    dfTestPredicted.loc[x] = [test['id'][x], predicted[x][1], predicted[x][2], predicted[x][3], predicted[x][4], predicted[x][5], predicted[x][6]]\n",
    "dfTestPredicted.to_csv('../reports/testPred/predTestCNN_Seq_'+ str(maxFeatures) +'.csv',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creaci칩n del modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(len(X_train_seq[0]), ))\n",
    "embed_size = 128\n",
    "x = Embedding(maxFeatures, embed_size)(inp)\n",
    "x = LSTM(90, return_sequences=True,name='lstm_layer')(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(60, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(7, activation=\"sigmoid\")(x)\n",
    "modelLSTM = Model(inputs=inp, outputs=x)\n",
    "modelLSTM.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTestResults = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV experiments\n",
    "idExp = 0\n",
    "X_train = X_train_seq\n",
    "X_test = X_test_seq\n",
    "numFeatures = maxFeatures\n",
    "\n",
    "# Cross validation\n",
    "Nfolds = 3\n",
    "kf = KFold(n_splits=Nfolds, random_state=True)\n",
    "kf.get_n_splits(X_train)\n",
    "\n",
    "name = \"LSTM\"\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "\n",
    "batch_size = 64 \n",
    "num_epochs = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in tqdm(kf.split(X_train)):\n",
    "    X_train_cv = X_train[train_index]\n",
    "    X_test_cv = X_train[test_index]\n",
    "    y_train_cv, y_test_cv = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    cnnmModelHist = modelLSTM.fit(X_train_cv, y_train_cv, batch_size=batch_size, epochs=num_epochs, validation_split=0.1, shuffle=True, verbose=2)\n",
    "    predicted = modelLSTM.predict(X_test_cv)\n",
    "\n",
    "    acc = accuracy_score(y_test_cv, predicted.round())\n",
    "    fmeausre = f1_score(y_test_cv, predicted.round(), labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted.round(), y_true=y_test_cv)\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "dfTestResults.loc[idExp] = [idExp,maxFeatures,name,Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "print(str(idExp))\n",
    "idExp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTestResults.to_excel('../reports/reportsCNN'+ str(maxFeatures) + '.xls', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicci칩n sobre test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso hacemos fitting mediante Tokenizaci칩n, debido a que para clasificar textos a partir de LSTM es la que mejor resultados da."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLSTM.fit(X_train_seq, y_train, batch_size=batch_size, epochs=min(num_epochs,2), validation_split=0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se almacenan los datos predecidos en formato CSV para poder hacer el submision de test, y poder evaluar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = modelLSTM.predict(X_test_seq, batch_size=1024, verbose=1)\n",
    "columns = [\"id\",\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "dfTestPredicted = pd.DataFrame(columns=columns)\n",
    "for x in tqdm(range(len(test))):\n",
    "    dfTestPredicted.loc[x] = [test['id'][x], predicted[x][1], predicted[x][2], predicted[x][3], predicted[x][4], predicted[x][5], predicted[x][6]]\n",
    "dfTestPredicted.to_csv('../reports/testPred/predTestLSTM_Seq_'+ str(maxFeatures) +'.csv',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
