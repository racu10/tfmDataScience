{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import ast\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from gensim import corpora, models, similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>listOfCleanWords</th>\n",
       "      <th>cleanWordsAsText</th>\n",
       "      <th>BagOfWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['explanation', 'edits', 'made', 'username', '...</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['aww', 'match', 'background', 'colour', 'seem...</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['hey', 'man', 'really', 'trying', 'edit', 'wa...</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['make', 'real', 'suggestion', 'improvement', ...</td>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sir', 'hero', 'chance', 'remember', 'page']</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['congratulation', 'well', 'use', 'tool', 'wel...</td>\n",
       "      <td>congratulation well use tool well talk</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['cocksucker', 'piss', 'around', 'work']</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['vandalism', 'matt', 'shirvington', 'article'...</td>\n",
       "      <td>vandalism matt shirvington article reverted pl...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sorry', 'word', 'nonsense', 'offensive', 'an...</td>\n",
       "      <td>sorry word nonsense offensive anyway intending...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['alignment', 'subject', 'contrary', 'dulithgow']</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "5           5  00025465d4725e87   \n",
       "6           6  0002bcb3da6cb337   \n",
       "7           7  00031b1e95af7921   \n",
       "8           8  00037261f536c51d   \n",
       "9           9  00040093b2687caa   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0             0   \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1             1   \n",
       "7  Your vandalism to the Matt Shirvington article...      0             0   \n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0             0   \n",
       "9  alignment on this subject and which are contra...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "5        0       0       0              0   \n",
       "6        1       0       1              0   \n",
       "7        0       0       0              0   \n",
       "8        0       0       0              0   \n",
       "9        0       0       0              0   \n",
       "\n",
       "                                    listOfCleanWords  \\\n",
       "0  ['explanation', 'edits', 'made', 'username', '...   \n",
       "1  ['aww', 'match', 'background', 'colour', 'seem...   \n",
       "2  ['hey', 'man', 'really', 'trying', 'edit', 'wa...   \n",
       "3  ['make', 'real', 'suggestion', 'improvement', ...   \n",
       "4      ['sir', 'hero', 'chance', 'remember', 'page']   \n",
       "5  ['congratulation', 'well', 'use', 'tool', 'wel...   \n",
       "6           ['cocksucker', 'piss', 'around', 'work']   \n",
       "7  ['vandalism', 'matt', 'shirvington', 'article'...   \n",
       "8  ['sorry', 'word', 'nonsense', 'offensive', 'an...   \n",
       "9  ['alignment', 'subject', 'contrary', 'dulithgow']   \n",
       "\n",
       "                                    cleanWordsAsText      BagOfWords  \n",
       "0  explanation edits made username hardcore metal...  <class 'dict'>  \n",
       "1  aww match background colour seemingly stuck th...  <class 'dict'>  \n",
       "2  hey man really trying edit war guy constantly ...  <class 'dict'>  \n",
       "3  make real suggestion improvement wondered sect...  <class 'dict'>  \n",
       "4                      sir hero chance remember page  <class 'dict'>  \n",
       "5             congratulation well use tool well talk  <class 'dict'>  \n",
       "6                        cocksucker piss around work  <class 'dict'>  \n",
       "7  vandalism matt shirvington article reverted pl...  <class 'dict'>  \n",
       "8  sorry word nonsense offensive anyway intending...  <class 'dict'>  \n",
       "9               alignment subject contrary dulithgow  <class 'dict'>  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameTrainCSV = 'trainWithListOfCleanWords'\n",
    "nameTestCSV = 'testWithListOfCleanWords'\n",
    "\n",
    "train = pd.read_csv('../data/processed/' + nameTrainCSV + '.csv', encoding='utf-8')\n",
    "train['BagOfWords'] = dict\n",
    "train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.686476230621338\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for x in range(len(train)):\n",
    "    train.set_value(col='listOfCleanWords',\n",
    "                index=x,\n",
    "                value=ast.literal_eval(train[\"listOfCleanWords\"][x]))\n",
    "    train.set_value(col='BagOfWords',\n",
    "                index=x,\n",
    "                value=Counter(train[\"listOfCleanWords\"][x]))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>listOfCleanWords</th>\n",
       "      <th>cleanWordsAsText</th>\n",
       "      <th>BagOfWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>{'explanation': 1, 'edits': 1, 'made': 1, 'use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[aww, match, background, colour, seemingly, st...</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "      <td>{'aww': 1, 'match': 1, 'background': 1, 'colou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>{'hey': 1, 'man': 1, 'really': 1, 'trying': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[make, real, suggestion, improvement, wondered...</td>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "      <td>{'make': 1, 'real': 1, 'suggestion': 1, 'impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>{'sir': 1, 'hero': 1, 'chance': 1, 'remember':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "\n",
       "                                    listOfCleanWords  \\\n",
       "0  [explanation, edits, made, username, hardcore,...   \n",
       "1  [aww, match, background, colour, seemingly, st...   \n",
       "2  [hey, man, really, trying, edit, war, guy, con...   \n",
       "3  [make, real, suggestion, improvement, wondered...   \n",
       "4                [sir, hero, chance, remember, page]   \n",
       "\n",
       "                                    cleanWordsAsText  \\\n",
       "0  explanation edits made username hardcore metal...   \n",
       "1  aww match background colour seemingly stuck th...   \n",
       "2  hey man really trying edit war guy constantly ...   \n",
       "3  make real suggestion improvement wondered sect...   \n",
       "4                      sir hero chance remember page   \n",
       "\n",
       "                                          BagOfWords  \n",
       "0  {'explanation': 1, 'edits': 1, 'made': 1, 'use...  \n",
       "1  {'aww': 1, 'match': 1, 'background': 1, 'colou...  \n",
       "2  {'hey': 1, 'man': 1, 'really': 1, 'trying': 1,...  \n",
       "3  {'make': 1, 'real': 1, 'suggestion': 1, 'impro...  \n",
       "4  {'sir': 1, 'hero': 1, 'chance': 1, 'remember':...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MULTICLASS PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classLabel = {\n",
    "    0: \"neutral\",\n",
    "    1: \"toxic\",\n",
    "    2 : \"severe_toxic\",\n",
    "    3 : \"obscene\",\n",
    "    4 : \"threat\",\n",
    "    5 : \"insult\",\n",
    "    6 : \"identity_hate\" \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.empty((len(train['cleanWordsAsText']),),dtype=object)\n",
    "allTextToxicTrain = dict()\n",
    "for idx in classLabel:\n",
    "    if classLabel[idx] != \"neutral\":\n",
    "        T = np.where(train[classLabel[idx]] == 1)[0]\n",
    "        allTextToxicTrain[idx] = T\n",
    "        for i in T:\n",
    "            if y[i] is None:\n",
    "                y[i] = [idx]                \n",
    "            else:\n",
    "                y[i].append(idx)\n",
    "indxsOfNeutralTexts = np.where(y == None) \n",
    "y[indxsOfNeutralTexts] = [[0]]\n",
    "indxsOfNeutralTexts = indxsOfNeutralTexts[0]\n",
    "\n",
    "allTextsNoToxicTrain = [str(train['cleanWordsAsText'][x]) for x in indxsOfNeutralTexts]\n",
    "\n",
    "idxList = []\n",
    "for i in allTextToxicTrain.keys():\n",
    "    #allTextToxicTrain[i] = [str(train['cleanWordsAsText'][j]) for j in allTextToxicTrain[i]]\n",
    "    idxList = np.unique(np.append(idxList, allTextToxicTrain[i]))\n",
    "allTextToxicTrain = [str(train['cleanWordsAsText'][j]) for j in idxList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\"idExp\",\"numFeatures\", \"algorithm\", \"Nfolds\", \"accuaracy\", \"logloss\", \"fmeasure\"]\n",
    "dfTestResults = pd.DataFrame(columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# listTopNFeatures = [10,50,100,200,500,1000]\n",
    "idExp = 0\n",
    "\n",
    "for topNFeatures in listTopNFeatures:\n",
    "    Nfolds = 5\n",
    "    ###### GET THE BEST WORDS IN ALL CORPUS #####\n",
    "    #Neutral data\n",
    "\n",
    "    tdidfVectTrainNoToxic = TfidfVectorizer(max_features=topNFeatures)\n",
    "    matrixTdidfTrainNoToxic = tdidfVectTrainNoToxic.fit_transform(allTextsNoToxicTrain)\n",
    "\n",
    "    featureArrayNoToxicTrain = np.array(tdidfVectTrainNoToxic.get_feature_names())\n",
    "    tfidfOrderedNoToxicTrain = np.argsort(matrixTdidfTrainNoToxic.toarray()).flatten()[::-1]\n",
    "    selectedWordsTrainNoToxic = featureArrayNoToxicTrain[tfidfOrderedNoToxicTrain][:topNFeatures]\n",
    "\n",
    "    #Toxic data\n",
    "    selectedWordsTrainToxic = []\n",
    "    selectedWordsTrain = []\n",
    "\n",
    "    tdidfVectTrainToxic = TfidfVectorizer(max_features=topNFeatures)\n",
    "    matrixTdidfTrainToxic = tdidfVectTrainToxic.fit_transform(allTextToxicTrain)\n",
    "    featureArrayToxicTrain = np.array(tdidfVectTrainToxic.get_feature_names())\n",
    "    tfidfOrderedToxicTrain = np.argsort(matrixTdidfTrainToxic.toarray()).flatten()[::-1]\n",
    "    selectedWordsTrainToxic = featureArrayToxicTrain[tfidfOrderedToxicTrain][:topNFeatures]\n",
    "\n",
    "    # Get words\n",
    "    for x in range(topNFeatures):\n",
    "        if len(selectedWordsTrain) <= topNFeatures: \n",
    "            words = [selectedWordsTrainToxic[x]] + [selectedWordsTrainNoToxic[x]]\n",
    "            selectedWordsTrain = np.unique(np.append(selectedWordsTrain, np.unique(words)))    \n",
    "    selectedWordsTrain = selectedWordsTrain[:topNFeatures]\n",
    "\n",
    "    allTrainText = [txt if txt is not np.nan else '' for txt in train['cleanWordsAsText']]\n",
    "\n",
    "    X = allTrainText\n",
    "    yBinary = MultiLabelBinarizer().fit_transform(y)\n",
    "\n",
    "    kf = KFold(n_splits=Nfolds, random_state=True)\n",
    "    kf.get_n_splits(allTrainText)\n",
    "    \n",
    "    print(str(topNFeatures))\n",
    "    #################################################################\n",
    "    # PREDICCION MULTICLASS Linear SVC\n",
    "\n",
    "    meanAcc = 0.0\n",
    "    meanLogLoss = 0.0\n",
    "    meanFmeasure = 0.0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train = [X[i] for i in train_index]\n",
    "        X_test = [X[i] for i in test_index]\n",
    "        y_train, y_test = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "        classifier = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(vocabulary=selectedWordsTrain)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', OneVsRestClassifier(LinearSVC()))])\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "        predicted = classifier.predict(X_test)\n",
    "        acc = accuracy_score(y_test, predicted)\n",
    "        fmeausre = f1_score(y_test, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "        logloss = log_loss(y_pred=predicted, y_true=y_test)\n",
    "        meanAcc += acc\n",
    "        meanLogLoss += logloss\n",
    "        meanFmeasure += fmeausre\n",
    "    meanAcc = meanAcc / Nfolds\n",
    "    meanLogLoss = meanLogLoss / Nfolds\n",
    "    meanFmeasure = meanFmeasure / Nfolds\n",
    "    dfTestResults.loc[idExp] = [idExp,topNFeatures,\"Linear SVC\",Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "    print(str(idExp))\n",
    "    idExp += 1\n",
    "\n",
    "    #################################################################\n",
    "    # PREDICCION MULTICLASS Decision Tree Classifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    meanAcc = 0.0\n",
    "    meanLogLoss = 0.0\n",
    "    meanFmeasure = 0.0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train = [X[i] for i in train_index]\n",
    "        X_test = [X[i] for i in test_index]\n",
    "        y_train, y_test = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "        classifier = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(vocabulary=selectedWordsTrain)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', OneVsRestClassifier(DecisionTreeClassifier()))])\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "        predicted = classifier.predict(X_test)\n",
    "        acc = accuracy_score(y_test, predicted)\n",
    "        fmeausre = f1_score(y_test, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "        logloss = log_loss(y_pred=predicted, y_true=y_test)\n",
    "        meanAcc += acc\n",
    "        meanLogLoss += logloss\n",
    "        meanFmeasure += fmeausre\n",
    "    meanAcc = meanAcc / Nfolds\n",
    "    meanLogLoss = meanLogLoss / Nfolds\n",
    "    meanFmeasure = meanFmeasure / Nfolds\n",
    "    dfTestResults.loc[idExp] = [idExp,topNFeatures,\"Decision Tree\",Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "    print(str(idExp))\n",
    "    idExp += 1\n",
    "    #################################################################\n",
    "    # PREDICCION MULTICLASS SGD\n",
    "    from sklearn import linear_model\n",
    "    meanAcc = 0.0\n",
    "    meanLogLoss = 0.0\n",
    "    meanFmeasure = 0.0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train = [X[i] for i in train_index]\n",
    "        X_test = [X[i] for i in test_index]\n",
    "        y_train, y_test = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "        classifier = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(vocabulary=selectedWordsTrain)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', OneVsRestClassifier(linear_model.SGDClassifier()))])\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "        predicted = classifier.predict(X_test)\n",
    "        acc = accuracy_score(y_test, predicted)\n",
    "        fmeausre = f1_score(y_test, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "        logloss = log_loss(y_pred=predicted, y_true=y_test)\n",
    "        meanAcc += acc\n",
    "        meanLogLoss += logloss\n",
    "        meanFmeasure += fmeausre\n",
    "    meanAcc = meanAcc / Nfolds\n",
    "    meanLogLoss = meanLogLoss / Nfolds\n",
    "    meanFmeasure = meanFmeasure / Nfolds\n",
    "    dfTestResults.loc[idExp] = [idExp,topNFeatures,\"SGD\",Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "    print(str(idExp))\n",
    "    idExp += 1\n",
    "    #################################################################\n",
    "    # PREDICCION MULTICLASS NB\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    meanAcc = 0.0\n",
    "    meanLogLoss = 0.0\n",
    "    meanFmeasure = 0.0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train = [X[i] for i in train_index]\n",
    "        X_test = [X[i] for i in test_index]\n",
    "        y_train, y_test = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "        classifier = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(vocabulary=selectedWordsTrain)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', OneVsRestClassifier(MultinomialNB()))])\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "        predicted = classifier.predict(X_test)\n",
    "        acc = accuracy_score(y_test, predicted)\n",
    "        fmeausre = f1_score(y_test, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "        logloss = log_loss(y_pred=predicted, y_true=y_test)\n",
    "        meanAcc += acc\n",
    "        meanLogLoss += logloss\n",
    "        meanFmeasure += fmeausre\n",
    "    meanAcc = meanAcc / Nfolds\n",
    "    meanLogLoss = meanLogLoss / Nfolds\n",
    "    meanFmeasure = meanFmeasure / Nfolds\n",
    "    dfTestResults.loc[idExp] = [idExp,topNFeatures,\"NB\",Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "    print(str(idExp))\n",
    "    idExp += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "writer = pd.ExcelWriter('../reports/' + 'results.xlsx')\n",
    "dfTestResults.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelWord2VecTrain = models.Word2Vec(train['listOfCleanWords'].tolist(), min_count=1)\n",
    "#say_vector = modelWord2VecTrain['explanation']  # get vector for word\n",
    "#say_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "C:\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "vectorizedTrainW2V = np.empty(len(train['listOfCleanWords']), dtype=list)\n",
    "for i, lstOfCleanWords in enumerate(train['listOfCleanWords']): \n",
    "    size = len(lstOfCleanWords)\n",
    "    if size > 0:\n",
    "        vector = np.zeros(len(modelWord2VecTrain[lstOfCleanWords[0]]))\n",
    "        for x in range(size):\n",
    "            vector += modelWord2VecTrain[lstOfCleanWords[x]]\n",
    "        vectorizedTrainW2V[i] = vector / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ array([ -3.00136152e-01,  -5.71729056e-01,  -4.96090920e-01,\n",
       "        -1.17840051e-01,  -6.81519689e-01,   1.59711916e-02,\n",
       "         4.99034632e-02,  -5.65436888e-01,  -3.31596926e-01,\n",
       "        -2.43633995e-01,  -1.11024374e-01,  -2.47723006e-01,\n",
       "        -2.08194790e-01,  -4.69958825e-02,  -1.05695644e-02,\n",
       "        -3.08239269e-02,  -4.90374701e-04,  -4.76884366e-01,\n",
       "         7.65669723e-01,  -3.59594397e-01,  -1.15618177e-01,\n",
       "         3.12664044e-01,   4.33685690e-01,   2.18956311e-01,\n",
       "        -1.04938791e-02,  -1.54937528e-01,  -2.14078129e-01,\n",
       "        -4.98786159e-01,   9.53592377e-01,   1.25305617e+00,\n",
       "        -5.68193221e-01,   8.00695183e-02,   8.92788202e-01,\n",
       "         7.43446916e-02,  -4.74748916e-01,   1.17665295e+00,\n",
       "        -3.20254573e-01,   5.71895715e-01,  -2.82631979e-01,\n",
       "        -2.29279274e-01,  -1.21729387e+00,  -4.88144905e-01,\n",
       "        -9.32447399e-01,  -4.94489278e-01,   6.45974980e-01,\n",
       "         5.75190730e-01,   1.51236555e-01,  -1.01207273e+00,\n",
       "         4.43065334e-01,  -1.00995638e-01,   4.30336373e-01,\n",
       "         1.15191840e-01,   2.32297831e-01,  -1.28144330e-01,\n",
       "         9.90418487e-01,  -9.47373535e-01,  -3.47177628e-01,\n",
       "        -5.57057183e-01,  -3.37211319e-01,   2.64291868e-01,\n",
       "        -2.31952784e-01,   1.17755519e-01,   2.30469437e-01,\n",
       "        -1.59041508e-01,   3.75270967e-02,  -3.47408430e-01,\n",
       "         1.40371397e-01,  -8.83604370e-01,  -4.14891027e-01,\n",
       "        -5.65031614e-01,  -6.15583582e-01,  -3.98820272e-01,\n",
       "         6.57713464e-01,  -2.63174701e-01,   1.98890301e-01,\n",
       "         3.59797030e-01,   3.75577658e-01,  -1.69574122e-01,\n",
       "         2.65199853e-04,   3.65208643e-01,   1.90309951e-01,\n",
       "         5.02042675e-01,  -1.54207996e-01,  -6.80760394e-01,\n",
       "        -4.33684884e-01,   1.21485234e-01,   7.52993201e-01,\n",
       "         3.76763429e-01,   8.06851001e-01,   7.72369758e-01,\n",
       "         4.37784988e-01,  -9.41949866e-01,   1.66788186e-01,\n",
       "         4.20704264e-01,  -3.36610456e-01,  -7.57084502e-01,\n",
       "         5.26078836e-01,  -5.46971780e-01,  -3.93661171e-01,\n",
       "        -1.59196446e-01]),\n",
       "       array([-0.41520768, -0.23237475, -0.8882874 ,  0.48408252, -0.09101879,\n",
       "        0.29319387, -0.04229536, -0.26468861, -0.52280515,  0.08147476,\n",
       "        0.4291347 , -0.55300996, -0.02293874, -0.26338432, -0.34256601,\n",
       "       -0.27814412,  0.16759657, -0.22446756,  0.20442265,  0.2111343 ,\n",
       "        0.06878716,  0.52409347,  0.29637911,  0.25922037,  0.09612812,\n",
       "        0.61213454, -0.18121155,  0.24136368,  0.5526284 , -0.04561217,\n",
       "       -0.09217657,  0.91946819,  0.92135422,  0.04438588,  0.10623145,\n",
       "        0.80085676, -0.03923849,  0.53137619,  0.14784784, -0.05095985,\n",
       "       -0.71958266, -0.19193354, -0.53407328, -0.25709802,  0.65710094,\n",
       "        0.77847593, -0.67549741, -0.12259904,  0.069895  , -0.35079195,\n",
       "        0.47159457, -0.19138654,  0.34043292,  0.39654624,  0.49615551,\n",
       "       -0.41394896, -0.18230139, -0.094931  , -0.2679183 ,  0.24807871,\n",
       "        0.35788723, -0.72764531, -0.2722277 , -0.11771355, -0.04434793,\n",
       "        0.240371  , -0.27094852, -1.32220328, -1.05689779, -0.49205255,\n",
       "       -0.43112727, -0.67212469,  0.69301714, -0.42028803, -0.03155099,\n",
       "        0.18684352,  0.10792472, -0.15424801, -0.4042478 ,  0.1870256 ,\n",
       "       -0.18527085,  0.22828308,  0.61562961, -0.90978913, -0.23446815,\n",
       "        0.20915202,  0.65957934,  0.67505467, -0.22559023, -0.48871464,\n",
       "        0.03718412, -0.35841057,  0.3168141 ,  0.03747321, -0.20570699,\n",
       "       -0.17463569,  0.21621187, -0.59362511, -0.63499647, -0.33778148]),\n",
       "       array([ 0.27991353, -0.06228407, -0.98059187, -0.50785579, -0.33381819,\n",
       "        0.23161684,  0.59231735, -0.47574426, -0.56360423,  0.09100987,\n",
       "        0.52577626,  0.40812048,  0.0656894 ,  0.16282131,  0.24107645,\n",
       "        0.05678185,  0.24555492, -0.69258602,  0.73336091, -0.10054027,\n",
       "       -0.18969476, -0.22250052,  0.42928176,  0.33245045,  0.21763941,\n",
       "       -0.02984477,  0.2596603 , -0.18925843,  1.49653636,  1.1233458 ,\n",
       "       -1.27356639,  1.43067507,  0.78785772,  0.35230828, -0.68067178,\n",
       "        0.8625893 , -0.50941542,  0.31167344, -0.24914633, -0.08438043,\n",
       "       -1.19019736, -1.00656105, -1.02091185, -0.33069275,  0.9620068 ,\n",
       "        0.69630131, -0.64752245, -1.15365767,  0.86884237, -0.53434959,\n",
       "        0.99535329,  1.00651193,  0.74399098,  0.0488639 ,  0.9548623 ,\n",
       "       -1.31702321,  0.14042568, -0.19536558, -0.62158941, -0.14167143,\n",
       "       -0.50527991, -0.30715873,  0.00276086,  0.70571552, -0.20444972,\n",
       "       -0.50935852,  0.62389509, -0.58270148, -0.06674655, -0.31707299,\n",
       "       -0.19985767,  0.0581016 ,  0.97485942,  0.32566481,  0.03347513,\n",
       "        0.1946189 ,  0.26898983, -0.02216053, -0.52603203,  0.56410742,\n",
       "       -0.87578914, -0.16672542,  0.19210786, -0.74450855,  0.17938701,\n",
       "        0.58343125,  0.62836385,  0.29618776,  0.95714143,  0.96636115,\n",
       "       -0.01628653, -1.17698875,  0.62586505,  0.56856356, -0.28389364,\n",
       "       -0.8208532 ,  0.32336471, -0.31211066, -0.61826495, -0.0941842 ]),\n",
       "       ...,\n",
       "       array([-0.68218896, -0.33684743, -0.49428599, -0.39015859, -0.4700159 ,\n",
       "        0.12746201,  0.0880862 , -0.38900979, -0.31192963,  0.21254724,\n",
       "        0.33646439, -0.35487943, -0.1395032 , -0.17981393,  0.04166119,\n",
       "       -0.1149089 , -0.18886104,  0.07681224, -0.03785752, -0.41907975,\n",
       "        0.4769139 , -0.00140979,  0.02965075,  0.13042756,  0.04783217,\n",
       "        0.01699478, -0.00404568,  0.27476134, -0.00202951,  0.38534853,\n",
       "        0.10544258,  0.46685558,  0.43708562, -0.25094224, -0.43616506,\n",
       "        0.18713129, -0.3112316 ,  0.45765338, -0.10562395,  0.05789169,\n",
       "       -0.16176739, -0.01325768, -0.45386123, -0.26044889,  0.25662204,\n",
       "        0.24264385,  0.06261921, -0.48442504,  0.05312786,  0.01631586,\n",
       "        0.12477894,  0.11463545,  0.57769441, -0.01913974,  0.38582165,\n",
       "       -0.15557046, -0.05233774, -0.12134018, -0.22664234,  0.1804134 ,\n",
       "       -0.44939607, -0.20319044,  0.12434854, -0.02708105,  0.19297017,\n",
       "       -0.31554969, -0.14322059,  0.1775642 , -0.19721904,  0.08009176,\n",
       "       -0.2421786 ,  0.40798495,  0.5710745 , -0.12565196,  0.11586283,\n",
       "        0.08902613,  0.01496024, -0.0682614 ,  0.14488311,  0.18707276,\n",
       "       -0.0342611 ,  0.05116488,  0.04204348, -0.57945013,  0.08786628,\n",
       "        0.23912918,  0.58655223, -0.04892453, -0.00615466,  0.14108411,\n",
       "       -0.04002077, -0.53978744,  0.27214446,  0.00275077, -0.3130273 ,\n",
       "       -0.23657321,  0.35953614, -0.20312345,  0.00726709,  0.47993867]),\n",
       "       array([-0.49505411, -0.02595143, -0.43452078, -0.02071876, -1.73609314,\n",
       "       -0.4715426 ,  0.18188576,  0.09483104, -0.592713  , -0.6284923 ,\n",
       "        0.03274259, -0.18002205, -0.02775786,  0.57515859,  0.20168204,\n",
       "        0.21083265, -1.16151519, -0.87318401,  0.30834727, -0.26391857,\n",
       "        0.37058987,  1.44693723,  0.85114431,  0.96580659, -0.29617386,\n",
       "       -0.38197956, -0.02542252,  1.12746939,  1.37460757,  1.43638405,\n",
       "       -0.12355191,  1.33838748,  1.0651785 ,  0.53322399, -0.76455749,\n",
       "        1.13325537,  0.55486734,  0.12764326,  0.03917623, -0.22545778,\n",
       "       -0.72523851, -0.06588453, -0.87249758,  0.13659189,  1.40955862,\n",
       "        0.23957078,  0.37539558, -0.57555591,  0.78549311, -1.36998225,\n",
       "        0.89077231,  0.71854438,  1.04462448,  0.58073251,  1.80442919,\n",
       "       -1.90012379, -0.27540423, -0.83696128, -0.1902572 , -0.30885   ,\n",
       "       -0.62421007, -0.18780948, -0.66823206,  0.02566608,  0.20644902,\n",
       "       -0.30584588, -1.0830406 , -1.54563834, -0.61792199, -0.89910841,\n",
       "       -1.71490983,  0.5125676 ,  0.76991091,  0.86200258,  0.17099954,\n",
       "        0.71354499, -0.33965211,  0.40922424, -0.14446904, -0.04751061,\n",
       "       -0.47260491, -0.69022485, -1.06702887, -1.74319945, -0.31219544,\n",
       "        1.16074031,  0.41606053,  1.21245711,  1.01395991,  0.86489685,\n",
       "       -0.44873022, -1.55396931,  0.39810486,  0.27038943,  0.43116381,\n",
       "       -0.76910233, -0.05172889, -0.79843183, -0.44243064,  1.42336826]),\n",
       "       array([-0.22552215, -0.28143044, -0.59786287, -0.45268218, -0.90781097,\n",
       "       -0.02588185,  1.2654028 , -0.14204794, -0.24625369,  0.59660023,\n",
       "        0.1594187 ,  0.28464789, -0.18003529,  0.16249255,  0.08847217,\n",
       "        0.2667347 , -0.36710524, -0.72778942,  0.31379394, -0.23516945,\n",
       "       -0.21265457,  0.20885891,  0.28358576, -0.33870435,  0.22265693,\n",
       "       -0.44943693,  0.65721555,  1.01820881,  0.8984205 ,  1.24739931,\n",
       "       -1.18619397,  1.83624545, -0.3180395 ,  0.13999022,  0.23963019,\n",
       "        0.50481041,  0.07625064, -0.09033417, -0.0667127 , -0.4202147 ,\n",
       "       -1.06562269, -0.6439833 , -1.09185171,  0.2073799 ,  1.31578224,\n",
       "        0.01861941, -0.66032679, -0.60709063,  0.69082017, -1.00483572,\n",
       "        0.75167665,  0.91203099,  1.23326277,  0.80093841,  1.03183393,\n",
       "       -2.06059146,  0.71040873, -0.48160583, -1.50373403,  0.27123303,\n",
       "       -0.76739185, -0.94450217, -0.71293408,  1.1430141 ,  0.39524827,\n",
       "       -1.40478312, -0.50408076,  0.40441926, -0.40079856, -0.86927675,\n",
       "        0.3411968 ,  0.08613065,  0.90940045,  0.59418854, -0.12404478,\n",
       "        0.60532452, -0.1863182 ,  0.71605422, -0.3127922 ,  0.01228702,\n",
       "       -0.42316812,  0.35368851,  0.9951736 , -0.83392106,  0.07209715,\n",
       "        0.19910817,  0.21426781,  0.22431452,  0.48332946,  1.01059655,\n",
       "       -0.02644533, -1.05983233,  0.50678786,  0.62247907, -0.26367109,\n",
       "       -0.30024142,  0.30584578, -1.24059018, -1.04125586, -0.06674626])], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizedTrainW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
