{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Ensambling de los diferentes algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### En este notebook, a partir de los resultados obtenidos por los diferentes algoritmos, haciendo uso de los que mayor porcentaje han tenido se generará ensambling entre estos según el peso indicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializacion variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfLR = None\n",
    "dfLSVC = None\n",
    "dfNB = None\n",
    "dfSGD = None\n",
    "dfDT = None\n",
    "\n",
    "#Deep Learning\n",
    "dfCNN = None\n",
    "dfLSTM = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lectura de todos los ficheros a tratar, se requerirá de un archivo CSV con todos los campos igual que un te test para en caso que un df no tenga valores por que sea comentado este será utilizado sin peso alguno en los resultados finales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/processed/ensambling/'\n",
    "\n",
    "# Se necesita de un archivo csv a modo de ejemplo para modificarlo totalmente, su contenido no será usado para nada.\n",
    "sample = pd.read_csv(path + 'novalidSample.csv', encoding='utf-8')\n",
    "\n",
    "\n",
    "#Machine learning\n",
    "dfLR = pd.read_csv(path + 'lr.csv', encoding='utf-8')\n",
    "dfLSVC = pd.read_csv(path + 'lsvc.csv', encoding='utf-8')\n",
    "dfNB = pd.read_csv(path + 'nb.csv', encoding='utf-8')\n",
    "dfSGD = pd.read_csv(path + 'sgd.csv', encoding='utf-8')\n",
    "dfDT = pd.read_csv(path + 'dt.csv', encoding='utf-8')\n",
    "\n",
    "#Deep Learning\n",
    "dfCNN = pd.read_csv(path + 'cnn.csv', encoding='utf-8')\n",
    "dfLSTM = pd.read_csv(path + 'lstm.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pesos para los diferentes algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wLR = 0.50\n",
    "wLSVC = 0.0\n",
    "wNB = 0.0\n",
    "wSGD = 0.0\n",
    "wDT = 0.0\n",
    "\n",
    "wCNN = 0.50\n",
    "wLSTM = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dfLR is None:\n",
    "    dfLR = sample\n",
    "    wLR = 0.0\n",
    "if dfLSVC is None:\n",
    "    dfLSVC = sample\n",
    "    wLSVC = 0.0\n",
    "if dfNB is None:\n",
    "    dfNB = sample\n",
    "    wNB = 0.0\n",
    "if dfSGD is None:\n",
    "    dfSGD = sample\n",
    "    wSGD = 0.0\n",
    "if dfDT is None:\n",
    "    dfDT = sample\n",
    "    wDT = 0.0\n",
    "if dfCNN is None:\n",
    "    dfCNN = sample\n",
    "    wCNN = 0.0\n",
    "if dfLSTM is None:\n",
    "    dfLSTM = sample\n",
    "    wLSTM = 0.0\n",
    "\n",
    "wTotal = sum([wLR, wLSTM, wNB, wSGD, wDT, wCNN, wLSTM])\n",
    "if wTotal != 1.0:\n",
    "    print(\"El peso total no es de 1. Es de --> \" + str(wTotal))\n",
    "else:\n",
    "    print(\"El peso es correcto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfEnd = sample.copy()\n",
    "dfEnd[columns] = (dfLR[columns] * wLR \n",
    "                  + dfLSVC[columns] * wLSVC \n",
    "                  + dfNB[columns] * wNB\n",
    "                  + dfSGD[columns] * wSGD\n",
    "                  + dfDT[columns] * wDT\n",
    "                  + dfCNN[columns] * wCNN\n",
    "                  + dfLSTM[columns] * wLSTM\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Exportación final del resputado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = \"ensambled\"\n",
    "dfEnd.to_csv(path + 'ensambled/' + name + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensambling por correlación de las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefDensidad = 0.1\n",
    "maxCorrelacion = 0.98\n",
    "\n",
    "# maxCorrelacion y coefDensidad Nunca puede ser superior a 1 o inferior a 0\n",
    "assert maxCorrelacion >= 0.0 and maxCorrelacion <= 1.0\n",
    "assert coefDensidad >= 0.0 and coefDensidad <= 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPredictions():\n",
    "    '''\n",
    "    Carga de todas las predicciones\n",
    "    '''\n",
    "    files = os.listdir(path)\n",
    "    lstCSVs = []\n",
    "    for f in files:\n",
    "        if f.endswith(\".csv\"):\n",
    "            lstCSVs.append(f)\n",
    "    frames = {f:pd.read_csv(path+f).sort_values('id') for f in lstCSVs}\n",
    "    return frames\n",
    "\n",
    "\n",
    "def getCorrelationMatrix(col,frames):\n",
    "    '''\n",
    "    Se obtiene la matriz de correlación\n",
    "    '''\n",
    "    corDf = pd.DataFrame()\n",
    "    for name, df in frames.items():\n",
    "        corDf[name] = df[col]\n",
    "    cor = corDf.corr()\n",
    "    for name in cor.columns:\n",
    "        cor.set_value(name,name,0.0)\n",
    "    return cor\n",
    "\n",
    "\n",
    "def getMaxCorrelation(matrixCorr):\n",
    "    '''\n",
    "    Se obtiene la correlación maxima de la matriz\n",
    "    '''\n",
    "    nCor = np.array(matrixCorr.values)\n",
    "    corr = np.max(nCor)\n",
    "    idx = np.unravel_index(np.argmax(nCor, axis=None), nCor.shape)\n",
    "    x1 = matrixCorr.columns[idx[0]]\n",
    "    x2 = matrixCorr.columns[idx[1]]\n",
    "    return corr,x1,x2\n",
    "\n",
    "\n",
    "def mergeDensitiesWeights(m1,m2,densities):\n",
    "    '''\n",
    "    Union de las densidades seún el peso y el coeficiente de densidad.\n",
    "    '''\n",
    "    d1 = densities[m1]\n",
    "    d2 = densities[m2]\n",
    "    d_tot = d1 + d2\n",
    "    weights1 = 0.5*coefDensidad + (d1/d_tot)*(1-coefDensidad)\n",
    "    weights2 = 0.5*coefDensidad + (d2/d_tot)*(1-coefDensidad)\n",
    "    return weights1, weights2\n",
    "\n",
    "\n",
    "def ensambleByColumn(col,frames,densities):\n",
    "    '''\n",
    "    Union de cada una \n",
    "    '''\n",
    "    if len(frames) == 1:\n",
    "        _, fr = frames.popitem()\n",
    "        return fr[col]\n",
    "\n",
    "    mat = getCorrelationMatrix(col,frames)\n",
    "    corr,merge1,merge2 = getMaxCorrelation(mat)\n",
    "    new_col_name = merge1 + '_' + merge2\n",
    "\n",
    "    w1,w2 = mergeDensitiesWeights(merge1,merge2,densities)\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df[col] = (frames[merge1][col]*w1) + (frames[merge2][col]*w2)\n",
    "    del frames[merge1]\n",
    "    del frames[merge2]\n",
    "    frames[new_col_name] = new_df\n",
    "\n",
    "    if corr >= maxCorrelacion:\n",
    "        print('\\t',merge1,merge2,' (OVER CORR)')\n",
    "        densities[new_col_name] = max(densities[merge1],densities[merge2])\n",
    "    else:\n",
    "        print('\\t',merge1,merge2)\n",
    "        densities[new_col_name] = densities[merge1] + densities[merge2]\n",
    "\n",
    "    del densities[merge1]\n",
    "    del densities[merge2]\n",
    "    #print(densities)\n",
    "    return ensambleByColumn(col,frames,densities)\n",
    "\n",
    "\n",
    "ensambled = sample.sort_values('id')\n",
    "\n",
    "for col in tqdm(columns):\n",
    "    frames = loadPredictions()\n",
    "    print('\\n\\n',col)\n",
    "    densities = {k:1.0 for k in frames.keys()}\n",
    "    ensambled[col] = ensambleByColumn(col,frames,densities)\n",
    "\n",
    "ensambled.to_csv(path + 'ensambled/ensambledByCorrelations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
