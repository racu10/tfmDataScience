{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Clasificación por machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### En este notebook, se procederá al uso de algoritmos esclusivamente de machine learning, mediante los datos que han sido previamente limpiados por \"Clean Words\". En este encontraremos en primer lugar, la realización de Cross Validation entre los datos de entrenamiento, y posteriormente se realizará una prediccion sobre los datos de Test. Para poder ser evaluados por Kaggle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import ast\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "# Linear Models \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameTrainCSV = 'trainWithListOfCleanWords'\n",
    "nameTestCSV = 'testWithListOfCleanWords'\n",
    "\n",
    "train = pd.read_csv('../data/processed/' + nameTrainCSV + '.csv', encoding='utf-8')\n",
    "train['BagOfWords'] = dict\n",
    "train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for x in range(len(train)):\n",
    "    train.set_value(col='listOfCleanWords',\n",
    "                index=x,\n",
    "                value=ast.literal_eval(train[\"listOfCleanWords\"][x]))\n",
    "    train.set_value(col='cleanWordsAsText',\n",
    "                index=x,\n",
    "                value=str(train[\"cleanWordsAsText\"][x]))\n",
    "    train.set_value(col='BagOfWords',\n",
    "                index=x,\n",
    "                value=Counter(train[\"listOfCleanWords\"][x]))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MULTICLASS PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classLabel = {\n",
    "    0: \"neutral\",\n",
    "    1: \"toxic\",\n",
    "    2 : \"severe_toxic\",\n",
    "    3 : \"obscene\",\n",
    "    4 : \"threat\",\n",
    "    5 : \"insult\",\n",
    "    6 : \"identity_hate\" \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get texts in Toxic and No Toxic\n",
    "y = np.empty((len(train['cleanWordsAsText']),),dtype=object)\n",
    "allTextToxicTrain = dict()\n",
    "for idx in classLabel:\n",
    "    if classLabel[idx] != \"neutral\":\n",
    "        T = np.where(train[classLabel[idx]] == 1)[0]\n",
    "        allTextToxicTrain[idx] = T\n",
    "        for i in T:\n",
    "            if y[i] is None:\n",
    "                y[i] = [idx]                \n",
    "            else:\n",
    "                y[i].append(idx)\n",
    "indxsOfNeutralTexts = np.where(y == None) \n",
    "y[indxsOfNeutralTexts] = [[0]]\n",
    "indxsOfNeutralTexts = indxsOfNeutralTexts[0]\n",
    "\n",
    "allTextsNoToxicTrain = [str(train['cleanWordsAsText'][x]) for x in indxsOfNeutralTexts]\n",
    "\n",
    "idxList = []\n",
    "for i in allTextToxicTrain.keys():\n",
    "    #allTextToxicTrain[i] = [str(train['cleanWordsAsText'][j]) for j in allTextToxicTrain[i]]\n",
    "    idxList = np.unique(np.append(idxList, allTextToxicTrain[i]))\n",
    "allTextToxicTrain = [str(train['cleanWordsAsText'][j]) for j in idxList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test clasification\n",
    "test = pd.read_csv('../data/processed/' + nameTestCSV + '.csv', encoding='utf-8')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se inicializan las variables de X_train y X_test + Y_train completos a partir de los textos ya limpios, ademas de obtener todos los textos en forma de lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allTrainText = [txt if txt is not np.nan else '' for txt in train['cleanWordsAsText']]\n",
    "allTestText = [txt if txt is not np.nan else '' for txt in test['cleanWordsAsText']]\n",
    "X_train = allTrainText\n",
    "X_test = allTestText\n",
    "yBinary = MultiLabelBinarizer().fit_transform(y)\n",
    "y_train = yBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\"idExp\",\"numFeatures\", \"algorithm\", \"Nfolds\", \"accuaracy\", \"logloss\", \"fmeasure\"]\n",
    "dfTestResults = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Clasificadores Machine Learning\n",
    "\n",
    "> Inicializamos los clasificadores con las variables a utilizar de cada uno de ellos. Los clasificadores a utilizar són:\n",
    "> - Regresión Logistica (LR)\n",
    "> - Máquinas de soporte vectorial con un kernel lineal (Linear SVC)\n",
    "> - Naive Bayes (NB)\n",
    "> - Stochastic Gradient Descent (SGD)\n",
    "> - Árbol de decisión (DT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Classifiers\n",
    "\n",
    "# Logistic Regresion\n",
    "clfLR = OneVsRestClassifier(LogisticRegression(C=5))\n",
    "\n",
    "# Linear SVC\n",
    "clfLSVC = OneVsRestClassifier(LinearSVC(C=5))\n",
    "\n",
    "# Naive Bayes\n",
    "clfNB = OneVsRestClassifier(MultinomialNB())\n",
    "\n",
    "# SGD\n",
    "clfSGD = OneVsRestClassifier(SGDClassifier(loss=\"log\"))\n",
    "\n",
    "# Decision Tree\n",
    "clfDT = OneVsRestClassifier(DecisionTreeClassifier(max_depth=8))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedings\n",
    "> En este apartado se diseñan 2 formas de representación de las palabras de los textos, utilizando directamente los textos ya limpiados previamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mediante vector TFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer all text\n",
    "maxF = 158627\n",
    "tdifV = TfidfVectorizer(ngram_range=(1,6), max_features=maxF)\n",
    "X_train_tdif = tdifV.fit_transform(allTrainText)\n",
    "\n",
    "numFeaturesTFID = len(tdifV.get_feature_names())\n",
    "print(\"NFeatures = \" + str(numFeaturesTFID))\n",
    "tdifVTest = TfidfVectorizer(vocabulary=tdifV.get_feature_names())\n",
    "X_test_tdif = tdifVTest.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mediante BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BOW\n",
    "bowFeatures = CountVectorizer(vocabulary=tdifV.get_feature_names())\n",
    "X_train_bow = bowFeatures.fit_transform(allTrainText)\n",
    "X_test_bow = bowFeatures.fit_transform(allTestText)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "> En este apartado se indicarán los parametros a tener en cuenta en los experimentos de train haciendo uso de CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "Nfolds = 5\n",
    "kf = KFold(n_splits=Nfolds, random_state=True)\n",
    "kf.get_n_splits(X_train_tdif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Para tener un seguimiento de los experimentos realizados, se dispondrá de un id de experimento, para númerar el experimento a realizar, que posteriormente estos serán guardados en formato excel.\n",
    "> Para la asignación X_train, está podrá ser asignada por cualquiera de los 2 word embedings creados previamente ya sea TFID o BOW. Además se deberá asignar el numFeatures del word embeding utilizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV experiments\n",
    "idExp = 0\n",
    "X_train = X_train_tdif\n",
    "X_test = X_test_tdif\n",
    "numFeatures = numFeaturesTFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LINEAR SVC CV exp\n",
    "name = \"Linear SVC\"\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_cv = X_train[train_index]\n",
    "    X_test_cv = X_train[test_index]\n",
    "    y_train_cv, y_test_cv = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    clfLSVC.fit(X_train_cv, y_train_cv)\n",
    "    predicted = clfLSVC.predict(X_test_cv)\n",
    "    acc = accuracy_score(y_test_cv, predicted)\n",
    "    fmeausre = f1_score(y_test_cv, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test_cv)\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "dfTestResults.loc[idExp] = [idExp,len(tdifV.get_feature_names()),name,Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "print(str(idExp))\n",
    "idExp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regresion CV exp\n",
    "name = \"Logistic Regresion\"\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_cv = X_train[train_index]\n",
    "    X_test_cv = X_train[test_index]\n",
    "    y_train_cv, y_test_cv = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    clfLR.fit(X_train_cv, y_train_cv)\n",
    "    predicted = clfLR.predict(X_test_cv)\n",
    "    acc = accuracy_score(y_test_cv, predicted)\n",
    "    fmeausre = f1_score(y_test_cv, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test_cv)\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "dfTestResults.loc[idExp] = [idExp,len(tdifV.get_feature_names()),name,Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "print(str(idExp))\n",
    "idExp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SGD CV exp\n",
    "name = \"SGD\"\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_cv = X_train[train_index]\n",
    "    X_test_cv = X_train[test_index]\n",
    "    y_train_cv, y_test_cv = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    clfSGD.fit(X_train_cv, y_train_cv)\n",
    "    predicted = clfSGD.predict(X_test_cv)\n",
    "    acc = accuracy_score(y_test_cv, predicted)\n",
    "    fmeausre = f1_score(y_test_cv, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test_cv)\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "dfTestResults.loc[idExp] = [idExp,len(tdifV.get_feature_names()),name,Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "print(str(idExp))\n",
    "idExp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NB CV exp\n",
    "name = \"NB\"\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_cv = X_train[train_index]\n",
    "    X_test_cv = X_train[test_index]\n",
    "    y_train_cv, y_test_cv = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    clfNB.fit(X_train_cv, y_train_cv)\n",
    "    predicted = clfNB.predict(X_test_cv)\n",
    "    acc = accuracy_score(y_test_cv, predicted)\n",
    "    fmeausre = f1_score(y_test_cv, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test_cv)\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "dfTestResults.loc[idExp] = [idExp,len(tdifV.get_feature_names()),name,Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "print(str(idExp))\n",
    "idExp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree CV exp\n",
    "name = \"Decision Tree\"\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_cv = X_train[train_index]\n",
    "    X_test_cv = X_train[test_index]\n",
    "    y_train_cv, y_test_cv = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    clfDT.fit(X_train_cv, y_train_cv)\n",
    "    predicted = clfDT.predict(X_test_cv)\n",
    "    acc = accuracy_score(y_test_cv, predicted)\n",
    "    fmeausre = f1_score(y_test_cv, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test_cv)\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "dfTestResults.loc[idExp] = [idExp,len(tdifV.get_feature_names()),name,Nfolds,meanAcc,meanLogLoss,meanFmeasure]\n",
    "print(str(idExp))\n",
    "idExp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTestResults.to_excel('../reports/reports'+ str(maxF) +'.xls', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de submisions de TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get submision from test\n",
    "def getCSVSubmision(prediction, name):\n",
    "    columns = [\"id\",\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "    dfTestPredicted = pd.DataFrame(columns=columns)\n",
    "    for x in tqdm(range(len(test))):\n",
    "        dfTestPredicted.loc[x] = [test['id'][x], prediction[x][1], prediction[x][2], prediction[x][3], prediction[x][4], prediction[x][5], prediction[x][6]]\n",
    "\n",
    "    dfTestPredicted.to_csv('../reports/testPred/'+ str(name) +'.csv',encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de pruebas para submision de test mediante TFID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train_tdif\n",
    "X_test = X_test_tdif\n",
    "numFeatures = numFeaturesTFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all clasificators with TFID matrix\n",
    "clfLSVC.fit(X_train, y_train)\n",
    "clfLR.fit(X_train, y_train)\n",
    "clfSGD.fit(X_train, y_train)\n",
    "clfNB.fit(X_train, y_train)\n",
    "clfDT.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addInfo = str(numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfLSVC.predict(X_test),name=\"LSVC_TFID\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfLR.predict_proba(X_test), name=\"LR_TFID\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfSGD.predict_proba(X_test), name=\"SGD_TFID\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfNB.predict_proba(X_test), name=\"NB_TFID\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfDT.predict_proba(X_test), name=\"DT_TFID\" + addInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creación de pruebas para submision de test mediante TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train_bow\n",
    "X_test = X_test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit all clasificators with TD matrix\n",
    "print(\"NFeatures = \" + str(len(tdifV.get_feature_names())))\n",
    "tdifVTest = TfidfVectorizer(vocabulary=tdifV.get_feature_names())\n",
    "X_test_tdif = tdifVTest.fit_transform(X_test)\n",
    "\n",
    "clfLSVC.fit(X_train, y_train)\n",
    "clfLR.fit(X_train, y_train)\n",
    "clfSGD.fit(X_train, y_train)\n",
    "clfNB.fit(X_train, y_train)\n",
    "clfDT.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfLSVC.predict(X_test),name=\"LSVC_TD\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfLR.predict_proba(X_test), name=\"LR_TD\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfSGD.predict_proba(X_test), name=\"SGD_TD\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfNB.predict_proba(X_test), name=\"NB_TD\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getCSVSubmision(prediction=clfDT.predict_proba(X_test), name=\"DT_TD\" + addInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
